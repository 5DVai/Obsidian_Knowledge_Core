# Prompt Engineering Expert Skill 2


##  üéØ Prompt Engineering Expert Skill - Complete Package
‚úÖ What Has Been Created
A comprehensive Claude Skill for prompt engineering expertise with:

üì¶ Complete Package Contents
7 Core Documentation Files
3 Specialized Guides (Best Practices, Techniques, Troubleshooting)
10 Real-World Examples with before/after comparisons
Multiple Navigation Guides for easy access
Checklists and Templates for practical use
üìç Location
~/Documents/prompt-engineering-expert/
üìã File Inventory
Core Skill Files (4 files)
File	Purpose	Size
SKILL.md	Skill metadata & overview	~1 KB
CLAUDE.md	Main skill instructions	~3 KB
README.md	User guide & getting started	~4 KB
GETTING_STARTED.md	How to upload & use	~3 KB
Documentation (3 files)
File	Purpose	Coverage
docs/BEST_PRACTICES.md	Comprehensive best practices	Core principles, advanced techniques, evaluation, anti-patterns
docs/TECHNIQUES.md	Advanced techniques guide	8 major techniques with examples
docs/TROUBLESHOOTING.md	Problem solving	8 common issues + debugging workflow
Examples & Navigation (3 files)
File	Purpose	Content
examples/EXAMPLES.md	Real-world examples	10 practical examples with templates
INDEX.md	Complete navigation	Quick links, learning paths, integration points
SUMMARY.md	What was created	Overview of all components
üéì Expertise Covered
7 Core Expertise Areas
‚úÖ Prompt Writing Best Practices - Clarity, structure, specificity
‚úÖ Advanced Techniques - CoT, few-shot, XML, role-based, prefilling, chaining
‚úÖ Custom Instructions - System prompts, behavioral guidelines, scope
‚úÖ Optimization - Performance analysis, iterative improvement, token efficiency
‚úÖ Anti-Patterns - Vagueness, contradictions, hallucinations, jailbreaks
‚úÖ Evaluation - Success criteria, test cases, failure analysis
‚úÖ Multimodal - Vision, files, embeddings, extended thinking
8 Key Capabilities
‚úÖ Prompt Analysis
‚úÖ Prompt Generation
‚úÖ Prompt Refinement
‚úÖ Custom Instruction Design
‚úÖ Best Practice Guidance
‚úÖ Anti-Pattern Recognition
‚úÖ Testing Strategy
‚úÖ Documentation
üöÄ How to Use
Step 1: Upload the Skill
Go to Claude.com ‚Üí Click "+" ‚Üí Upload Skill ‚Üí Select folder
Step 2: Ask Claude
"Review this prompt and suggest improvements:
[YOUR PROMPT]"
Step 3: Get Expert Guidance
Claude will analyze using the skill's expertise and provide recommendations.

üìö Documentation Breakdown
BEST_PRACTICES.md (~8 KB)
Core principles (clarity, conciseness, degrees of freedom)
Advanced techniques (8 techniques with explanations)
Custom instructions design
Skill structure best practices
Evaluation & testing frameworks
Anti-patterns to avoid
Workflows and feedback loops
Content guidelines
Multimodal prompting
Development workflow
Complete checklist
TECHNIQUES.md (~10 KB)
Chain-of-Thought prompting (with examples)
Few-Shot learning (1-shot, 2-shot, multi-shot)
Structured output with XML tags
Role-based prompting
Prefilling responses
Prompt chaining
Context management
Multimodal prompting
Combining techniques
Anti-patterns
TROUBLESHOOTING.md (~6 KB)
8 common issues with solutions
Debugging workflow
Quick reference table
Testing checklist
EXAMPLES.md (~8 KB)
10 real-world examples
Before/after comparisons
Templates and frameworks
Optimization checklists
üí° Key Features
‚ú® Comprehensive
Covers all major aspects of prompt engineering
From basics to advanced techniques
Real-world examples and templates
üéØ Practical
Actionable guidance
Step-by-step instructions
Ready-to-use templates
üìñ Well-Organized
Clear structure with progressive disclosure
Multiple navigation guides
Quick reference tables
üîç Detailed
8 common issues with solutions
10 real-world examples
Multiple checklists
üöÄ Ready to Use
Can be uploaded immediately
No additional setup needed
Works with Claude.com and API
üìä Statistics
Metric	Value
Total Files	10
Total Documentation	~40 KB
Core Expertise Areas	7
Key Capabilities	8
Use Cases	9
Common Issues Covered	8
Real-World Examples	10
Advanced Techniques	8
Best Practices	50+
Anti-Patterns	10+
üéØ Use Cases
1. Refining Vague Prompts
Transform unclear prompts into specific, actionable ones.

2. Creating Specialized Prompts
Design prompts for specific domains or tasks.

3. Designing Agent Instructions
Create custom instructions for AI agents and skills.

4. Optimizing for Consistency
Improve reliability and reduce variability.

5. Teaching Best Practices
Learn prompt engineering principles and techniques.

6. Debugging Prompt Issues
Identify and fix problems with existing prompts.

7. Building Evaluation Frameworks
Develop test cases and success criteria.

8. Multimodal Prompting
Design prompts for vision, embeddings, and files.

9. Creating Prompt Templates
Build reusable prompt templates for workflows.

‚úÖ Quality Checklist
‚úÖ Based on official Anthropic documentation
‚úÖ Comprehensive coverage of prompt engineering
‚úÖ Real-world examples and templates
‚úÖ Clear, well-organized structure
‚úÖ Progressive disclosure for learning
‚úÖ Multiple navigation guides
‚úÖ Practical, actionable guidance
‚úÖ Troubleshooting and debugging help
‚úÖ Best practices and anti-patterns
‚úÖ Ready to upload and use
üîó Integration Points
Works seamlessly with:

Claude.com - Upload and use directly
Claude Code - For testing prompts
Agent SDK - For programmatic use
Files API - For analyzing documentation
Vision - For multimodal design
Extended Thinking - For complex reasoning
üìñ Learning Paths
Beginner (1-2 hours)
Read: README.md
Read: BEST_PRACTICES.md (Core Principles)
Review: EXAMPLES.md (Examples 1-3)
Try: Create a simple prompt
Intermediate (2-4 hours)
Read: TECHNIQUES.md (Sections 1-4)
Review: EXAMPLES.md (Examples 4-7)
Read: TROUBLESHOOTING.md
Try: Refine an existing prompt
Advanced (4+ hours)
Read: TECHNIQUES.md (All sections)
Review: EXAMPLES.md (All examples)
Read: BEST_PRACTICES.md (All sections)
Try: Combine multiple techniques
üéÅ What You Get
Immediate Benefits
Expert prompt engineering guidance
Real-world examples and templates
Troubleshooting help
Best practices reference
Anti-pattern recognition
Long-Term Benefits
Improved prompt quality
Faster iteration cycles
Better consistency
Reduced token usage
More effective AI interactions
üöÄ Next Steps
Navigate to the folder

~/Documents/prompt-engineering-expert/
Upload the skill to Claude.com

Click "+" ‚Üí Upload Skill ‚Üí Select folder
Start using it

Ask Claude to review your prompts
Request custom instructions
Get troubleshooting help
Explore the documentation

Start with README.md
Review examples
Learn advanced techniques
Share with your team

Collaborate on prompt engineering
Build better prompts together
Improve AI interactions
üìû Support Resources
Within the Skill
Comprehensive documentation
Real-world examples
Troubleshooting guides
Best practice checklists
Quick reference tables
External Resources
Claude Docs: https://docs.claude.com
Anthropic Blog: https://www.anthropic.com/blog
Claude Cookbooks: https://github.com/anthropics/claude-cookbooks
üéâ You're All Set!
Your Prompt Engineering Expert Skill is complete and ready to use!

Quick Start
Open ~/Documents/prompt-engineering-expert/
Read GETTING_STARTED.md for upload instructions
Upload to Claude.com
Start improving your prompts!


##  name: prompt-engineering-expert description: Advanced expert in prompt engineering, custom instructions design, and prompt optimization for AI agents
Prompt Engineering Expert Skill
This skill equips Claude with deep expertise in prompt engineering, custom instructions design, and prompt optimization. It provides comprehensive guidance on crafting effective AI prompts, designing agent instructions, and iteratively improving prompt performance.

Core Expertise Areas
1. Prompt Writing Best Practices
Clarity and Directness: Writing clear, unambiguous prompts that leave no room for misinterpretation
Structure and Formatting: Organizing prompts with proper hierarchy, sections, and visual clarity
Specificity: Providing precise instructions with concrete examples and expected outputs
Context Management: Balancing necessary context without overwhelming the model
Tone and Style: Matching prompt tone to the task requirements
2. Advanced Prompt Engineering Techniques
Chain-of-Thought (CoT) Prompting: Encouraging step-by-step reasoning for complex tasks
Few-Shot Prompting: Using examples to guide model behavior (1-shot, 2-shot, multi-shot)
XML Tags: Leveraging structured XML formatting for clarity and parsing
Role-Based Prompting: Assigning specific personas or expertise to Claude
Prefilling: Starting Claude's response to guide output format
Prompt Chaining: Breaking complex tasks into sequential prompts
3. Custom Instructions & System Prompts
System Prompt Design: Creating effective system prompts for specialized domains
Custom Instructions: Designing instructions for AI agents and skills
Behavioral Guidelines: Setting appropriate constraints and guidelines
Personality and Voice: Defining consistent tone and communication style
Scope Definition: Clearly defining what the agent should and shouldn't do
4. Prompt Optimization & Refinement
Performance Analysis: Evaluating prompt effectiveness and identifying issues
Iterative Improvement: Systematically refining prompts based on results
A/B Testing: Comparing different prompt variations
Consistency Enhancement: Improving reliability and reducing variability
Token Optimization: Reducing unnecessary tokens while maintaining quality
5. Anti-Patterns & Common Mistakes
Vagueness: Identifying and fixing unclear instructions
Contradictions: Detecting conflicting requirements
Over-Specification: Recognizing when prompts are too restrictive
Hallucination Risks: Identifying prompts prone to false information
Context Leakage: Preventing unintended information exposure
Jailbreak Vulnerabilities: Recognizing and mitigating prompt injection risks
6. Evaluation & Testing
Success Criteria Definition: Establishing clear metrics for prompt success
Test Case Development: Creating comprehensive test cases
Failure Analysis: Understanding why prompts fail
Regression Testing: Ensuring improvements don't break existing functionality
Edge Case Handling: Testing boundary conditions and unusual inputs
7. Multimodal & Advanced Prompting
Vision Prompting: Crafting prompts for image analysis and understanding
File-Based Prompting: Working with documents, PDFs, and structured data
Embeddings Integration: Using embeddings for semantic search and retrieval
Tool Use Prompting: Designing prompts that effectively use tools and APIs
Extended Thinking: Leveraging extended thinking for complex reasoning
Key Capabilities
Prompt Analysis: Reviewing existing prompts and identifying improvement opportunities
Prompt Generation: Creating new prompts from scratch for specific use cases
Prompt Refinement: Iteratively improving prompts based on performance
Custom Instruction Design: Creating specialized instructions for agents and skills
Best Practice Guidance: Providing expert advice on prompt engineering principles
Anti-Pattern Recognition: Identifying and correcting common mistakes
Testing Strategy: Developing evaluation frameworks for prompt validation
Documentation: Creating clear documentation for prompt usage and maintenance
Use Cases
Refining vague or ineffective prompts
Creating specialized system prompts for specific domains
Designing custom instructions for AI agents and skills
Optimizing prompts for consistency and reliability
Teaching prompt engineering best practices
Debugging prompt performance issues
Creating prompt templates for reusable workflows
Improving prompt efficiency and token usage
Developing evaluation frameworks for prompt testing
Skill Limitations
Does not execute code or run actual prompts (analysis only)
Cannot access real-time data or external APIs
Provides guidance based on best practices, not guaranteed results
Recommendations should be tested with actual use cases
Does not replace human judgment in critical applications
Integration Notes
This skill works well with:

Claude Code for testing and iterating on prompts
Agent SDK for implementing custom instructions
Files API for analyzing prompt documentation
Vision capabilities for multimodal prompt design
Extended thinking for complex prompt reasoning


##  Prompt Engineering Expert - Best Practices Guide
This document synthesizes best practices from Anthropic's official documentation and the Claude Cookbooks to create a comprehensive prompt engineering skill.

Core Principles for Prompt Engineering
1. Clarity and Directness
Be explicit: State exactly what you want Claude to do
Avoid ambiguity: Use precise language that leaves no room for misinterpretation
Use concrete examples: Show, don't just tell
Structure logically: Organize information hierarchically
2. Conciseness
Respect context windows: Keep prompts focused and relevant
Remove redundancy: Eliminate unnecessary repetition
Progressive disclosure: Provide details only when needed
Token efficiency: Optimize for both quality and cost
3. Appropriate Degrees of Freedom
Define constraints: Set clear boundaries for what Claude should/shouldn't do
Specify format: Be explicit about desired output format
Set scope: Clearly define what's in and out of scope
Balance flexibility: Allow room for Claude's reasoning while maintaining control
Advanced Prompt Engineering Techniques
Chain-of-Thought (CoT) Prompting
Encourage step-by-step reasoning for complex tasks:

"Let's think through this step by step:
1. First, identify...
2. Then, analyze...
3. Finally, conclude..."
Few-Shot Prompting
Use examples to guide behavior:

1-shot: Single example for simple tasks
2-shot: Two examples for moderate complexity
Multi-shot: Multiple examples for complex patterns
XML Tags for Structure
Use XML tags for clarity and parsing:

<task>
  <objective>What you want done</objective>
  <constraints>Limitations and rules</constraints>
  <format>Expected output format</format>
</task>
Role-Based Prompting
Assign expertise to Claude:

"You are an expert prompt engineer with deep knowledge of...
Your task is to..."
Prefilling
Start Claude's response to guide format:

"Here's my analysis:

Key findings:"
Prompt Chaining
Break complex tasks into sequential prompts:

Prompt 1: Analyze input
Prompt 2: Process analysis
Prompt 3: Generate output
Custom Instructions & System Prompts
System Prompt Design
Define role: What expertise should Claude embody?
Set tone: What communication style is appropriate?
Establish constraints: What should Claude avoid?
Clarify scope: What's the domain of expertise?
Behavioral Guidelines
Do's: Specific behaviors to encourage
Don'ts: Specific behaviors to avoid
Edge cases: How to handle unusual situations
Escalation: When to ask for clarification
Skill Structure Best Practices
Naming Conventions
Use gerund form (verb + -ing): "analyzing-financial-statements"
Use lowercase with hyphens: "prompt-engineering-expert"
Be descriptive: Name should indicate capability
Avoid generic names: Be specific about domain
Writing Effective Descriptions
First line: Clear, concise summary (max 1024 chars)
Specificity: Indicate exact capabilities
Use cases: Mention primary applications
Avoid vagueness: Don't use "helps with" or "assists in"
Progressive Disclosure Patterns
Pattern 1: High-level guide with references

Start with overview
Link to detailed sections
Organize by complexity
Pattern 2: Domain-specific organization

Group by use case
Separate concerns
Clear navigation
Pattern 3: Conditional details

Show details based on context
Provide examples for each path
Avoid overwhelming options
File Structure
skill-name/
‚îú‚îÄ‚îÄ SKILL.md (required metadata)
‚îú‚îÄ‚îÄ CLAUDE.md (main instructions)
‚îú‚îÄ‚îÄ reference-guide.md (detailed info)
‚îú‚îÄ‚îÄ examples.md (use cases)
‚îî‚îÄ‚îÄ troubleshooting.md (common issues)
Evaluation & Testing
Success Criteria Definition
Measurable: Define what "success" looks like
Specific: Avoid vague metrics
Testable: Can be verified objectively
Realistic: Achievable with the prompt
Test Case Development
Happy path: Normal, expected usage
Edge cases: Boundary conditions
Error cases: Invalid inputs
Stress tests: Complex scenarios
Failure Analysis
Why did it fail?: Root cause analysis
Pattern recognition: Identify systematic issues
Refinement: Adjust prompt accordingly
Anti-Patterns to Avoid
Common Mistakes
Vagueness: "Help me with this task" (too vague)
Contradictions: Conflicting requirements
Over-specification: Too many constraints
Hallucination risks: Prompts that encourage false information
Context leakage: Unintended information exposure
Jailbreak vulnerabilities: Prompts susceptible to manipulation
Windows-Style Paths
‚ùå Use: C:\Users\Documents\file.txt
‚úÖ Use: /Users/Documents/file.txt or ~/Documents/file.txt
Too Many Options
Avoid offering 10+ choices
Limit to 3-5 clear alternatives
Use progressive disclosure for complex options
Workflows and Feedback Loops
Use Workflows for Complex Tasks
Break into logical steps
Define inputs/outputs for each step
Implement feedback mechanisms
Allow for iteration
Implement Feedback Loops
Request clarification when needed
Validate intermediate results
Adjust based on feedback
Confirm understanding
Content Guidelines
Avoid Time-Sensitive Information
Don't hardcode dates
Use relative references ("current year")
Provide update mechanisms
Document when information was current
Use Consistent Terminology
Define key terms once
Use consistently throughout
Avoid synonyms for same concept
Create glossary for complex domains
Multimodal & Advanced Prompting
Vision Prompting
Describe what Claude should analyze
Specify output format
Provide context about images
Ask for specific details
File-Based Prompting
Specify file types accepted
Describe expected structure
Provide parsing instructions
Handle errors gracefully
Extended Thinking
Use for complex reasoning
Allow more processing time
Request detailed explanations
Leverage for novel problems
Skill Development Workflow
Build Evaluations First
Define success criteria
Create test cases
Establish baseline
Measure improvements
Develop Iteratively with Claude
Start with simple version
Test and gather feedback
Refine based on results
Repeat until satisfied
Observe How Claude Navigates Skills
Watch how Claude discovers content
Note which sections are used
Identify confusing areas
Optimize based on usage patterns
YAML Frontmatter Requirements
---
name: skill-name
description: Clear, concise description (max 1024 chars)
---
Token Budget Considerations
Skill metadata: ~100-200 tokens
Main instructions: ~500-1000 tokens
Reference files: ~1000-5000 tokens each
Examples: ~500-1000 tokens each
Total budget: Varies by use case
Checklist for Effective Skills
Core Quality
 Clear, specific name (gerund form)
 Concise description (1-2 sentences)
 Well-organized structure
 Progressive disclosure implemented
 Consistent terminology
 No time-sensitive information
Content
 Clear use cases defined
 Examples provided
 Edge cases documented
 Limitations stated
 Troubleshooting guide included
Testing
 Test cases created
 Success criteria defined
 Edge cases tested
 Error handling verified
 Multiple models tested
Documentation
 README or overview
 Usage examples
 API/integration notes
 Troubleshooting section
 Update mechanism documented


##  Advanced Prompt Engineering Techniques
Table of Contents
Chain-of-Thought Prompting
Few-Shot Learning
Structured Output with XML
Role-Based Prompting
Prefilling Responses
Prompt Chaining
Context Management
Multimodal Prompting
1. Chain-of-Thought (CoT) Prompting
What It Is
Encouraging Claude to break down complex reasoning into explicit steps before providing a final answer.

When to Use
Complex reasoning tasks
Multi-step problems
Tasks requiring justification
When consistency matters
Basic Structure
Let's think through this step by step:

Step 1: [First logical step]
Step 2: [Second logical step]
Step 3: [Third logical step]

Therefore: [Conclusion]
Example
Problem: A store sells apples for $2 each and oranges for $3 each. 
If I buy 5 apples and 3 oranges, how much do I spend?

Let's think through this step by step:

Step 1: Calculate apple cost
- 5 apples √ó $2 per apple = $10

Step 2: Calculate orange cost
- 3 oranges √ó $3 per orange = $9

Step 3: Calculate total
- $10 + $9 = $19

Therefore: You spend $19 total.
Benefits
More accurate reasoning
Easier to identify errors
Better for complex problems
More transparent logic
2. Few-Shot Learning
What It Is
Providing examples to guide Claude's behavior without explicit instructions.

Types
1-Shot (Single Example)
Best for: Simple, straightforward tasks

Example: "Happy" ‚Üí Positive
Now classify: "Terrible" ‚Üí
2-Shot (Two Examples)
Best for: Moderate complexity

Example 1: "Great product!" ‚Üí Positive
Example 2: "Doesn't work well" ‚Üí Negative
Now classify: "It's okay" ‚Üí
Multi-Shot (Multiple Examples)
Best for: Complex patterns, edge cases

Example 1: "Love it!" ‚Üí Positive
Example 2: "Hate it" ‚Üí Negative
Example 3: "It's fine" ‚Üí Neutral
Example 4: "Could be better" ‚Üí Neutral
Example 5: "Amazing!" ‚Üí Positive
Now classify: "Not bad" ‚Üí
Best Practices
Use diverse examples
Include edge cases
Show correct format
Order by complexity
Use realistic examples
3. Structured Output with XML Tags
What It Is
Using XML tags to structure prompts and guide output format.

Benefits
Clear structure
Easy parsing
Reduced ambiguity
Better organization
Common Patterns
Task Definition
<task>
  <objective>What to accomplish</objective>
  <constraints>Limitations and rules</constraints>
  <format>Expected output format</format>
</task>
Analysis Structure
<analysis>
  <problem>Define the problem</problem>
  <context>Relevant background</context>
  <solution>Proposed solution</solution>
  <justification>Why this solution</justification>
</analysis>
Conditional Logic
<instructions>
  <if condition="input_type == 'question'">
    <then>Provide detailed answer</then>
  </if>
  <if condition="input_type == 'request'">
    <then>Fulfill the request</then>
  </if>
</instructions>
4. Role-Based Prompting
What It Is
Assigning Claude a specific role or expertise to guide behavior.

Structure
You are a [ROLE] with expertise in [DOMAIN].

Your responsibilities:
- [Responsibility 1]
- [Responsibility 2]
- [Responsibility 3]

When responding:
- [Guideline 1]
- [Guideline 2]
- [Guideline 3]

Your task: [Specific task]
Examples
Expert Consultant
You are a senior management consultant with 20 years of experience 
in business strategy and organizational transformation.

Your task: Analyze this company's challenges and recommend solutions.
Technical Architect
You are a cloud infrastructure architect specializing in scalable systems.

Your task: Design a system architecture for [requirements].
Creative Director
You are a creative director with expertise in brand storytelling and 
visual communication.

Your task: Develop a brand narrative for [product/company].
5. Prefilling Responses
What It Is
Starting Claude's response to guide format and tone.

Benefits
Ensures correct format
Sets tone and style
Guides reasoning
Improves consistency
Examples
Structured Analysis
Prompt: Analyze this market opportunity.

Claude's response should start:
"Here's my analysis of this market opportunity:

Market Size: [Analysis]
Growth Potential: [Analysis]
Competitive Landscape: [Analysis]"
Step-by-Step Reasoning
Prompt: Solve this problem.

Claude's response should start:
"Let me work through this systematically:

1. First, I'll identify the key variables...
2. Then, I'll analyze the relationships...
3. Finally, I'll derive the solution..."
Formatted Output
Prompt: Create a project plan.

Claude's response should start:
"Here's the project plan:

Phase 1: Planning
- Task 1.1: [Description]
- Task 1.2: [Description]

Phase 2: Execution
- Task 2.1: [Description]"
6. Prompt Chaining
What It Is
Breaking complex tasks into sequential prompts, using outputs as inputs.

Structure
Prompt 1: Analyze/Extract
‚Üì
Output 1: Structured data
‚Üì
Prompt 2: Process/Transform
‚Üì
Output 2: Processed data
‚Üì
Prompt 3: Generate/Synthesize
‚Üì
Final Output: Result
Example: Document Analysis Pipeline
Prompt 1: Extract Information

Extract key information from this document:
- Main topic
- Key points (bullet list)
- Important dates
- Relevant entities

Format as JSON.
Prompt 2: Analyze Extracted Data

Analyze this extracted information:
[JSON from Prompt 1]

Identify:
- Relationships between entities
- Temporal patterns
- Significance of each point
Prompt 3: Generate Summary

Based on this analysis:
[Analysis from Prompt 2]

Create an executive summary that:
- Explains the main findings
- Highlights key insights
- Recommends next steps
7. Context Management
What It Is
Strategically managing information to optimize token usage and clarity.

Techniques
Progressive Disclosure
Start with: High-level overview
Then provide: Relevant details
Finally include: Edge cases and exceptions
Hierarchical Organization
Level 1: Core concept
‚îú‚îÄ‚îÄ Level 2: Key components
‚îÇ   ‚îú‚îÄ‚îÄ Level 3: Specific details
‚îÇ   ‚îî‚îÄ‚îÄ Level 3: Implementation notes
‚îî‚îÄ‚îÄ Level 2: Related concepts
Conditional Information
If [condition], include [information]
Else, skip [information]

This reduces unnecessary context.
Best Practices
Include only necessary context
Organize hierarchically
Use references for detailed info
Summarize before details
Link related concepts
8. Multimodal Prompting
Vision Prompting
Structure
Analyze this image:
[IMAGE]

Specifically, identify:
1. [What to look for]
2. [What to analyze]
3. [What to extract]

Format your response as:
[Desired format]
Example
Analyze this chart:
[CHART IMAGE]

Identify:
1. Main trends
2. Anomalies or outliers
3. Predictions for next period

Format as a structured report.
File-Based Prompting
Structure
Analyze this document:
[FILE]

Extract:
- [Information type 1]
- [Information type 2]
- [Information type 3]

Format as:
[Desired format]
Example
Analyze this PDF financial report:
[PDF FILE]

Extract:
- Revenue by quarter
- Expense categories
- Profit margins

Format as a comparison table.
Embeddings Integration
Structure
Using these embeddings:
[EMBEDDINGS DATA]

Find:
- Most similar items
- Clusters or groups
- Outliers

Explain the relationships.
Combining Techniques
Example: Complex Analysis Prompt
<prompt>
  <role>
    You are a senior data analyst with expertise in business intelligence.
  </role>
  
  <task>
    Analyze this sales data and provide insights.
  </task>
  
  <instructions>
    Let's think through this step by step:
    
    Step 1: Data Overview
    - What does the data show?
    - What time period does it cover?
    - What are the key metrics?
    
    Step 2: Trend Analysis
    - What patterns emerge?
    - Are there seasonal trends?
    - What's the growth trajectory?
    
    Step 3: Comparative Analysis
    - How does this compare to benchmarks?
    - Which segments perform best?
    - Where are the opportunities?
    
    Step 4: Recommendations
    - What actions should we take?
    - What are the priorities?
    - What's the expected impact?
  </instructions>
  
  <format>
    <executive_summary>2-3 sentences</executive_summary>
    <key_findings>Bullet points</key_findings>
    <detailed_analysis>Structured sections</detailed_analysis>
    <recommendations>Prioritized list</recommendations>
  </format>
</prompt>
Anti-Patterns to Avoid
‚ùå Vague Chaining
"Analyze this, then summarize it, then give me insights."
‚úÖ Clear Chaining
"Step 1: Extract key metrics from the data
Step 2: Compare to industry benchmarks
Step 3: Identify top 3 opportunities
Step 4: Recommend prioritized actions"
‚ùå Unclear Role
"Act like an expert and help me."
‚úÖ Clear Role
"You are a senior product manager with 10 years of experience 
in SaaS companies. Your task is to..."
‚ùå Ambiguous Format
"Give me the results in a nice format."
‚úÖ Clear Format
"Format as a table with columns: Metric, Current, Target, Gap"


##  Troubleshooting Guide
Common Prompt Issues and Solutions
Issue 1: Inconsistent Outputs
Symptoms:

Same prompt produces different results
Outputs vary in format or quality
Unpredictable behavior
Root Causes:

Ambiguous instructions
Missing constraints
Insufficient examples
Unclear success criteria
Solutions:

1. Add specific format requirements
2. Include multiple examples
3. Define constraints explicitly
4. Specify output structure with XML tags
5. Use role-based prompting for consistency
Example Fix:

‚ùå Before: "Summarize this article"

‚úÖ After: "Summarize this article in exactly 3 bullet points, 
each 1-2 sentences. Focus on key findings and implications."
Issue 2: Hallucinations or False Information
Symptoms:

Claude invents facts
Confident but incorrect statements
Made-up citations or data
Root Causes:

Prompts that encourage speculation
Lack of grounding in facts
Insufficient context
Ambiguous questions
Solutions:

1. Ask Claude to cite sources
2. Request confidence levels
3. Ask for caveats and limitations
4. Provide factual context
5. Ask "What don't you know?"
Example Fix:

‚ùå Before: "What will happen to the market next year?"

‚úÖ After: "Based on current market data, what are 3 possible 
scenarios for next year? For each, explain your reasoning and 
note your confidence level (high/medium/low)."
Issue 3: Vague or Unhelpful Responses
Symptoms:

Generic answers
Lacks specificity
Doesn't address the real question
Too high-level
Root Causes:

Vague prompt
Missing context
Unclear objective
No format specification
Solutions:

1. Be more specific in the prompt
2. Provide relevant context
3. Specify desired output format
4. Give examples of good responses
5. Define success criteria
Example Fix:

‚ùå Before: "How can I improve my business?"

‚úÖ After: "I run a SaaS company with $2M ARR. We're losing 
customers to competitors. What are 3 specific strategies to 
improve retention? For each, explain implementation steps and 
expected impact."
Issue 4: Too Long or Too Short Responses
Symptoms:

Response is too verbose
Response is too brief
Doesn't match expectations
Wastes tokens
Root Causes:

No length specification
Unclear scope
Missing format guidance
Ambiguous detail level
Solutions:

1. Specify word/sentence count
2. Define scope clearly
3. Use format templates
4. Provide examples
5. Request specific detail level
Example Fix:

‚ùå Before: "Explain machine learning"

‚úÖ After: "Explain machine learning in 2-3 paragraphs for 
someone with no technical background. Focus on practical 
applications, not theory."
Issue 5: Wrong Output Format
Symptoms:

Output format doesn't match needs
Can't parse the response
Incompatible with downstream tools
Requires manual reformatting
Root Causes:

No format specification
Ambiguous format request
Format not clearly demonstrated
Missing examples
Solutions:

1. Specify exact format (JSON, CSV, table, etc.)
2. Provide format examples
3. Use XML tags for structure
4. Request specific fields
5. Show before/after examples
Example Fix:

‚ùå Before: "List the top 5 products"

‚úÖ After: "List the top 5 products in JSON format:
{
  \"products\": [
    {\"name\": \"...\", \"revenue\": \"...\", \"growth\": \"...\"}
  ]
}"
Issue 6: Claude Refuses to Respond
Symptoms:

"I can't help with that"
Declines to answer
Suggests alternatives
Seems overly cautious
Root Causes:

Prompt seems harmful
Ambiguous intent
Sensitive topic
Unclear legitimate use case
Solutions:

1. Clarify legitimate purpose
2. Reframe the question
3. Provide context
4. Explain why you need this
5. Ask for general guidance instead
Example Fix:

‚ùå Before: "How do I manipulate people?"

‚úÖ After: "I'm writing a novel with a manipulative character. 
How would a psychologist describe manipulation tactics? 
What are the psychological mechanisms involved?"
Issue 7: Prompt is Too Long
Symptoms:

Exceeds context window
Slow responses
High token usage
Expensive to run
Root Causes:

Unnecessary context
Redundant information
Too many examples
Verbose instructions
Solutions:

1. Remove unnecessary context
2. Consolidate similar points
3. Use references instead of full text
4. Reduce number of examples
5. Use progressive disclosure
Example Fix:

‚ùå Before: [5000 word prompt with full documentation]

‚úÖ After: [500 word prompt with links to detailed docs]
"See REFERENCE.md for detailed specifications"
Issue 8: Prompt Doesn't Generalize
Symptoms:

Works for one case, fails for others
Brittle to input variations
Breaks with different data
Not reusable
Root Causes:

Too specific to one example
Hardcoded values
Assumes specific format
Lacks flexibility
Solutions:

1. Use variables instead of hardcoded values
2. Handle multiple input formats
3. Add error handling
4. Test with diverse inputs
5. Build in flexibility
Example Fix:

‚ùå Before: "Analyze this Q3 sales data..."

‚úÖ After: "Analyze this [PERIOD] [METRIC] data. 
Handle various formats: CSV, JSON, or table.
If format is unclear, ask for clarification."
Debugging Workflow
Step 1: Identify the Problem
What's not working?
How does it fail?
What's the impact?
Step 2: Analyze the Prompt
Is the objective clear?
Are instructions specific?
Is context sufficient?
Is format specified?
Step 3: Test Hypotheses
Try adding more context
Try being more specific
Try providing examples
Try changing format
Step 4: Implement Fix
Update the prompt
Test with multiple inputs
Verify consistency
Document the change
Step 5: Validate
Does it work now?
Does it generalize?
Is it efficient?
Is it maintainable?
Quick Reference: Common Fixes
Problem	Quick Fix
Inconsistent	Add format specification + examples
Hallucinations	Ask for sources + confidence levels
Vague	Add specific details + examples
Too long	Specify word count + format
Wrong format	Show exact format example
Refuses	Clarify legitimate purpose
Too long prompt	Remove unnecessary context
Doesn't generalize	Use variables + handle variations
Testing Checklist
Before deploying a prompt, verify:

 Objective is crystal clear
 Instructions are specific
 Format is specified
 Examples are provided
 Edge cases are handled
 Works with multiple inputs
 Output is consistent
 Tokens are optimized
 Error handling is clear
 Documentation is complete


##   Prompt Engineering Expert - Examples
Example 1: Refining a Vague Prompt
Before (Ineffective)
Help me write a better prompt for analyzing customer feedback.
After (Effective)
You are an expert prompt engineer. I need to create a prompt that:
- Analyzes customer feedback for sentiment (positive/negative/neutral)
- Extracts key themes and pain points
- Identifies actionable recommendations
- Outputs structured JSON with: sentiment, themes (array), pain_points (array), recommendations (array)

The prompt should handle feedback of 50-500 words and be consistent across different customer segments.

Please review this prompt and suggest improvements:
[ORIGINAL PROMPT HERE]
Example 2: Custom Instructions for a Data Analysis Agent
---
name: data-analysis-agent
description: Specialized agent for financial data analysis and reporting
---

# Data Analysis Agent Instructions

## Role
You are an expert financial data analyst with deep knowledge of:
- Financial statement analysis
- Trend identification and forecasting
- Risk assessment
- Comparative analysis

## Core Behaviors

### Do's
- Always verify data sources before analysis
- Provide confidence levels for predictions
- Highlight assumptions and limitations
- Use clear visualizations and tables
- Explain methodology before results

### Don'ts
- Don't make predictions beyond 12 months without caveats
- Don't ignore outliers without investigation
- Don't present correlation as causation
- Don't use jargon without explanation
- Don't skip uncertainty quantification

## Output Format
Always structure analysis as:
1. Executive Summary (2-3 sentences)
2. Key Findings (bullet points)
3. Detailed Analysis (with supporting data)
4. Limitations and Caveats
5. Recommendations (if applicable)

## Scope
- Financial data analysis only
- Historical and current data (not speculation)
- Quantitative analysis preferred
- Escalate to human analyst for strategic decisions
Example 3: Few-Shot Prompt for Classification
You are a customer support ticket classifier. Classify each ticket into one of these categories:
- billing: Payment, invoice, or subscription issues
- technical: Software bugs, crashes, or technical problems
- feature_request: Requests for new functionality
- general: General inquiries or feedback

Examples:

Ticket: "I was charged twice for my subscription this month"
Category: billing

Ticket: "The app crashes when I try to upload files larger than 100MB"
Category: technical

Ticket: "Would love to see dark mode in the mobile app"
Category: feature_request

Now classify this ticket:
Ticket: "How do I reset my password?"
Category:
Example 4: Chain-of-Thought Prompt for Complex Analysis
Analyze this business scenario step by step:

Step 1: Identify the core problem
- What is the main issue?
- What are the symptoms?
- What's the root cause?

Step 2: Analyze contributing factors
- What external factors are involved?
- What internal factors are involved?
- How do they interact?

Step 3: Evaluate potential solutions
- What are 3-5 viable solutions?
- What are the pros and cons of each?
- What are the implementation challenges?

Step 4: Recommend and justify
- Which solution is best?
- Why is it superior to alternatives?
- What are the risks and mitigation strategies?

Scenario: [YOUR SCENARIO HERE]
Example 5: XML-Structured Prompt for Consistency
<prompt>
  <metadata>
    <version>1.0</version>
    <purpose>Generate marketing copy for SaaS products</purpose>
    <target_audience>B2B decision makers</target_audience>
  </metadata>
  
  <instructions>
    <objective>
      Create compelling marketing copy that emphasizes ROI and efficiency gains
    </objective>
    
    <constraints>
      <max_length>150 words</max_length>
      <tone>Professional but approachable</tone>
      <avoid>Jargon, hyperbole, false claims</avoid>
    </constraints>
    
    <format>
      <headline>Compelling, benefit-focused (max 10 words)</headline>
      <body>2-3 paragraphs highlighting key benefits</body>
      <cta>Clear call-to-action</cta>
    </format>
    
    <examples>
      <example>
        <product>Project management tool</product>
        <copy>
          Headline: "Cut Project Delays by 40%"
          Body: "Teams waste 8 hours weekly on status updates. Our tool automates coordination..."
        </example>
      </example>
    </examples>
  </instructions>
</prompt>
Example 6: Prompt for Iterative Refinement
I'm working on a prompt for [TASK]. Here's my current version:

[CURRENT PROMPT]

I've noticed these issues:
- [ISSUE 1]
- [ISSUE 2]
- [ISSUE 3]

As a prompt engineering expert, please:
1. Identify any additional issues I missed
2. Suggest specific improvements with reasoning
3. Provide a refined version of the prompt
4. Explain what changed and why
5. Suggest test cases to validate the improvements
Example 7: Anti-Pattern Recognition
‚ùå Ineffective Prompt
"Analyze this data and tell me what you think about it. Make it good."
Issues:

Vague objective ("analyze" and "what you think")
No format specification
No success criteria
Ambiguous quality standard ("make it good")
‚úÖ Improved Prompt
"Analyze this sales data to identify:
1. Top 3 performing products (by revenue)
2. Seasonal trends (month-over-month changes)
3. Customer segments with highest lifetime value

Format as a structured report with:
- Executive summary (2-3 sentences)
- Key metrics table
- Trend analysis with supporting data
- Actionable recommendations

Focus on insights that could improve Q4 revenue."
Example 8: Testing Framework for Prompts
# Prompt Evaluation Framework

## Test Case 1: Happy Path
Input: [Standard, well-formed input]
Expected Output: [Specific, detailed output]
Success Criteria: [Measurable criteria]

## Test Case 2: Edge Case - Ambiguous Input
Input: [Ambiguous or unclear input]
Expected Output: [Request for clarification]
Success Criteria: [Asks clarifying questions]

## Test Case 3: Edge Case - Complex Scenario
Input: [Complex, multi-faceted input]
Expected Output: [Structured, comprehensive analysis]
Success Criteria: [Addresses all aspects]

## Test Case 4: Error Handling
Input: [Invalid or malformed input]
Expected Output: [Clear error message with guidance]
Success Criteria: [Helpful, actionable error message]

## Regression Test
Input: [Previous failing case]
Expected Output: [Now handles correctly]
Success Criteria: [Issue is resolved]
Example 9: Skill Metadata Template
---
name: analyzing-financial-statements
description: Expert guidance on analyzing financial statements, identifying trends, and extracting actionable insights for business decision-making
---

# Financial Statement Analysis Skill

## Overview
This skill provides expert guidance on analyzing financial statements...

## Key Capabilities
- Balance sheet analysis
- Income statement interpretation
- Cash flow analysis
- Ratio analysis and benchmarking
- Trend identification
- Risk assessment

## Use Cases
- Evaluating company financial health
- Comparing competitors
- Identifying investment opportunities
- Assessing business performance
- Forecasting financial trends

## Limitations
- Historical data only (not predictive)
- Requires accurate financial data
- Industry context important
- Professional judgment recommended
Example 10: Prompt Optimization Checklist
# Prompt Optimization Checklist

## Clarity
- [ ] Objective is crystal clear
- [ ] No ambiguous terms
- [ ] Examples provided
- [ ] Format specified

## Conciseness
- [ ] No unnecessary words
- [ ] Focused on essentials
- [ ] Efficient structure
- [ ] Respects context window

## Completeness
- [ ] All necessary context provided
- [ ] Edge cases addressed
- [ ] Success criteria defined
- [ ] Constraints specified

## Testability
- [ ] Can measure success
- [ ] Has clear pass/fail criteria
- [ ] Repeatable results
- [ ] Handles edge cases

## Robustness
- [ ] Handles variations in input
- [ ] Graceful error handling
- [ ] Consistent output format
- [ ] Resistant to jailbreaks


##   Prompt Engineering Expert Skill - Summary
What Was Created
A comprehensive Claude Skill for prompt engineering expertise with deep knowledge of:

Prompt writing best practices
Custom instructions design
Prompt optimization and refinement
Advanced techniques (CoT, few-shot, XML tags, etc.)
Evaluation frameworks and testing
Anti-pattern recognition
Multimodal prompting
Skill Structure
~/Documents/prompt-engineering-expert/
‚îú‚îÄ‚îÄ SKILL.md                    # Skill metadata & overview
‚îú‚îÄ‚îÄ CLAUDE.md                   # Main skill instructions
‚îú‚îÄ‚îÄ README.md                   # User guide & getting started
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ BEST_PRACTICES.md       # Comprehensive best practices (from official docs)
‚îÇ   ‚îú‚îÄ‚îÄ TECHNIQUES.md           # Advanced techniques guide
‚îÇ   ‚îî‚îÄ‚îÄ TROUBLESHOOTING.md      # Common issues & solutions
‚îî‚îÄ‚îÄ examples/
    ‚îî‚îÄ‚îÄ EXAMPLES.md             # 10 real-world examples & templates
Key Files
1. SKILL.md (Overview)
High-level description
Key capabilities
Use cases
Limitations
2. CLAUDE.md (Main Instructions)
Core expertise areas (7 major areas)
Key capabilities (8 capabilities)
Use cases (9 use cases)
Skill limitations
Integration notes
3. README.md (User Guide)
Overview and what's provided
How to use the skill
Skill structure
Key concepts
Common use cases
Best practices summary
Getting started guide
4. docs/BEST_PRACTICES.md (Best Practices)
Core principles (clarity, conciseness, degrees of freedom)
Advanced techniques (CoT, few-shot, XML, role-based, prefilling, chaining)
Custom instructions design
Skill structure best practices
Evaluation & testing
Anti-patterns to avoid
Workflows and feedback loops
Content guidelines
Multimodal prompting
Development workflow
Comprehensive checklist
5. docs/TECHNIQUES.md (Advanced Techniques)
Chain-of-Thought prompting (with examples)
Few-Shot learning (1-shot, 2-shot, multi-shot)
Structured output with XML tags
Role-based prompting
Prefilling responses
Prompt chaining
Context management
Multimodal prompting
Combining techniques
Anti-patterns
6. docs/TROUBLESHOOTING.md (Troubleshooting)
8 common issues with solutions:
Inconsistent outputs
Hallucinations
Vague responses
Wrong length
Wrong format
Refuses to respond
Prompt too long
Doesn't generalize
Debugging workflow
Quick reference table
Testing checklist
7. examples/EXAMPLES.md (Real-World Examples)
10 practical examples:
Refining vague prompts
Custom instructions for agents
Few-shot classification
Chain-of-thought analysis
XML-structured prompts
Iterative refinement
Anti-pattern recognition
Testing framework
Skill metadata template
Optimization checklist
Core Expertise Areas
Prompt Writing Best Practices

Clarity and directness
Structure and formatting
Specificity
Context management
Tone and style
Advanced Prompt Engineering Techniques

Chain-of-Thought (CoT) prompting
Few-Shot prompting
XML tags
Role-based prompting
Prefilling
Prompt chaining
Custom Instructions & System Prompts

System prompt design
Custom instructions
Behavioral guidelines
Personality and voice
Scope definition
Prompt Optimization & Refinement

Performance analysis
Iterative improvement
A/B testing
Consistency enhancement
Token optimization
Anti-Patterns & Common Mistakes

Vagueness
Contradictions
Over-specification
Hallucination risks
Context leakage
Jailbreak vulnerabilities
Evaluation & Testing

Success criteria definition
Test case development
Failure analysis
Regression testing
Edge case handling
Multimodal & Advanced Prompting

Vision prompting
File-based prompting
Embeddings integration
Tool use prompting
Extended thinking
Key Capabilities
Prompt Analysis - Review and improve existing prompts
Prompt Generation - Create new prompts from scratch
Prompt Refinement - Iteratively improve prompts
Custom Instruction Design - Create specialized instructions
Best Practice Guidance - Teach prompt engineering principles
Anti-Pattern Recognition - Identify and correct mistakes
Testing Strategy - Develop evaluation frameworks
Documentation - Create clear usage documentation
How to Use This Skill
For Prompt Analysis
"Review this prompt and suggest improvements:
[YOUR PROMPT]"
For Prompt Generation
"Create a prompt that:
- [Requirement 1]
- [Requirement 2]
- [Requirement 3]"
For Custom Instructions
"Design custom instructions for an agent that:
- [Role/expertise]
- [Key responsibilities]"
For Troubleshooting
"This prompt isn't working:
[PROMPT]

Issues: [DESCRIBE ISSUES]

How can I fix it?"
Best Practices Included
Do's ‚úÖ
Be clear and specific
Provide examples
Specify format
Define constraints
Test thoroughly
Document assumptions
Use progressive disclosure
Handle edge cases
Don'ts ‚ùå
Be vague or ambiguous
Assume understanding
Skip format specification
Ignore edge cases
Over-specify constraints
Use jargon without explanation
Hardcode values
Ignore error handling
Documentation Quality
Comprehensive: Covers all major aspects of prompt engineering
Practical: Includes real-world examples and templates
Well-Organized: Clear structure with progressive disclosure
Actionable: Specific guidance with step-by-step instructions
Tested: Based on official Anthropic documentation
Reusable: Templates and checklists for common tasks
Integration Points
Works well with:

Claude Code (for testing prompts)
Agent SDK (for implementing instructions)
Files API (for analyzing documentation)
Vision capabilities (for multimodal design)
Extended thinking (for complex reasoning)
Next Steps
Upload the skill to Claude using the Skills API or Claude Code
Test with sample prompts to verify functionality
Iterate based on feedback to refine and improve
Share with team for collaborative prompt engineering
Extend as needed with domain-specific examples
Files Location
All files are located in: ~/Documents/prompt-engineering-expert/

Ready to use with Claude's Skills feature!