# Large Language Models (LLMs) Reference Manual for OpenRouter
**Source:** LLM reference manual.pdf  
**Ingestion Date:** 2025-11-28

## Executive Summary
The "LLM Reference Manual for OpenRouter" serves as a comprehensive guide for selecting and utilizing large language models (LLMs) through the OpenRouter platform. OpenRouter aggregates LLMs from various providers, offering a unified API to switch between models based on task requirements. This manual provides detailed insights into model capabilities, context lengths, pricing, and specialized features, enabling developers to make informed decisions that balance cost and performance. The document is particularly valuable for enterprises seeking to optimize their use of LLMs for diverse applications, from general chat and coding to complex reasoning and multilingual tasks.

The manual emphasizes the importance of selecting the right model for specific tasks to reduce costs and improve output quality. It includes strategies for cost management, such as model chaining and caching, and provides a detailed comparison of major LLMs available on OpenRouter as of August 2025. This resource is essential for developers and architects aiming to leverage LLMs effectively within their organizations, ensuring that they can meet both technical and budgetary constraints.

## Key Concepts & Principles
- **Model Selection:** Align model strengths with task requirements to optimize performance and cost.
- **Cost Management:** Implement strategies like model chaining and caching to minimize expenses.
- **Context Length:** Choose models with appropriate context lengths to handle the complexity of tasks.
- **Capabilities:** Consider models' support for tool-calling, code generation, and multimodal input.
- **Pricing Structure:** Understand the cost implications of input and output tokens across different models.

## Detailed Technical Analysis

### Model Selection and Cost Management
The manual outlines a strategic approach to model selection, emphasizing the need to match model capabilities with task requirements. High-end models like GPT-5 and Claude Opus are recommended for tasks demanding top quality, while more cost-effective models like GPT-3.5 Turbo and Mistral Medium are suitable for less demanding applications. The document also highlights cost-saving strategies, such as workflow chaining and caching, which can significantly reduce operational expenses.

### Context Length and Capabilities
Different models offer varying context lengths, impacting their suitability for tasks involving long documents or complex reasoning. For instance, Gemini Flash provides an impressive 1 million token context, ideal for extensive documents. The manual also discusses models' capabilities, such as tool-calling and retrieval-augmented generation, which enhance their performance in specific scenarios.

### Pricing and Performance Trade-offs
The manual provides a detailed comparison of input and output costs across models, enabling developers to assess the trade-offs between performance and expense. For example, GPT-5 offers high accuracy but at a premium cost, while models like DeepSeek V3 provide competitive performance at a lower price point.

## Enterprise Q&A Bank

1. **Q:** How can I reduce costs when using high-end LLMs for complex tasks?
   **A:** Consider using workflow chaining to break tasks into smaller steps and employ different models for each step, reducing overall costs by 30-60%.

2. **Q:** What should I consider when selecting a model for multilingual tasks?
   **A:** Choose models like GPT-4o, Claude models, or Mistral Large 2, which offer strong multilingual support and can handle diverse language requirements.

3. **Q:** How do I decide between using GPT-5 and GPT-5 Mini?
   **A:** Use GPT-5 for tasks requiring the highest accuracy and reasoning depth. Opt for GPT-5 Mini when you need similar quality at a lower cost and latency.

4. **Q:** What are the benefits of using OpenRouter for LLM integration?
   **A:** OpenRouter provides a unified API for accessing multiple LLMs, simplifying model switching and integration while offering a wide range of models to suit different tasks.

5. **Q:** How can I ensure my application remains cost-effective over time?
   **A:** Regularly review model pricing and performance updates on OpenRouter, and adjust your model selection and cost-saving strategies accordingly.

## Actionable Takeaways
- **Align Model and Task:** Ensure the selected model's strengths align with the task requirements to optimize performance and cost.
- **Implement Cost-Saving Strategies:** Use model chaining, caching, and batching to reduce expenses.
- **Monitor Pricing Changes:** Stay informed about pricing updates on OpenRouter to maintain cost-effectiveness.
- **Leverage Multimodal Capabilities:** Utilize models like GPT-4o and Gemini Flash for tasks requiring text and image processing.
- **Optimize for Context Length:** Select models with sufficient context length to handle the complexity of your tasks without truncation.

---
**Raw Content:**  
Reference Manual on Large Language Models (LLMs) for OpenRouter (August 26 2025) Introduction OpenRouter.ai acts as an aggregator of large language models (LLMs) from multiple providers, offering a single API for switching between models. Each model differs in context length (the maximum number of tokens that can be processed in one request), pricing, and specialized capabilities. Selecting the right model for a given prompt can reduce costs and improve quality. This manual compiles information from various provider pages and independent analyses about models available on OpenRouter as of 26 August 2025 . How to use this manual Model selection : Identify the purpose of your prompt (e.g., general chat, coding, complex reasoning, multilingual tasks) and choose a model whose strengths align with your use‑case. Use the Summary tables for quick comparison, then read the Details sections for nuance. Cost management : Models vary significantly in price. High‑end models deliver top performance but can be costly. For less demanding tasks, lower‑cost or free models can suffice. The Cost‑saving strategies section outlines tactics such as model chaining and caching. Context length : Larger contexts allow longer conversations or bigger documents. Choose models with sufficient context to avoid truncating important information. Capabilities : Some models support tool‑calling, code generation, retrieval‑augmented generation (RAG), or multimodal input (text and images). These features influence performance on certain tasks. Summary of Major LLMs on OpenRouter The table below summarises many prominent models available through OpenRouter as of August 2025. Costs are given per one million tokens unless noted otherwise. (For free models the cost is zero; some models charge search or usage fees separately.) Provider & Model Context Length Input Cost (USD/ M tokens) Output Cost (USD/M tokens) Key strengths/notes OpenAI GPT‑5 Chat 400 k 1.25 10 GPT‑5 Mini 400 k 0.25 2 GPT‑5 Nano 400 k 0.05 0.40 GPT‑4o (Omni) 128 k 2.50 10 • • • • 1 1 2 2 3 3 4 4 1

Provider & Model Context Length Input Cost (USD/ M tokens) Output Cost (USD/M tokens) Key strengths/notes GPT‑4 Turbo 128 k 10 30 GPT‑3.5 Turbo 16 k 0.50 1.50 Anthropic Claude Opus 4 (4.1) 200 k 15 75 Claude Sonnet 4 200 k 3 15 Claude Haiku 3.5 200 k 0.80 4 DeepSeek DeepSeek V3 163.8 k 0.20 0.80 DeepSeek V3.1 163.8 k 0.0002 per token ( ≈ 0.20/ M) 0.0008 per token ( ≈ 0.80/ M) DeepSeek Coder V2 128 k 0.27 1.10 DeepSeek Chat (free) 16 k 0 0 Mistral Mistral Large 2 128 k 2 6 Mistral Medium 3.1 131 k 0.40 2 Codestral (Code‑centric) 32 k 1 3 Mistral Small 3.1 (free) 128 k 0 0 Z.AI (GLM) GLM‑4.5 (“Thinking”) 131 k 2 per K? (pricing in JSON: 0.0000004 input 0.0000016 output ≈ 0.40/ M & 1.60/M) ?? (depends on variant) Qwen Qwen‑3‑30B (MoE) 262 k 0.10 per M 【 598919971721685†L308- L406 】 0.30 per M 【 598919971721685†L308- L406 】 Qwen‑3‑235B (Thinking) 262 k ≈ 0.078 per M 【 598919971721685†L308- L406 】 ≈ 0.312 per M 【 598919971721685†L308- L406 】 Qwen QwQ 32B (free) 128 k 0 0 AI21 Jamba Large 256 k 0.0006 per token ( ≈ 0.60/ M) 0.0024 per token ( ≈ 2.40/ M) Jamba Mini 256 k 0.0002 per token ( ≈ 0.20/ M) 0.0008 per token ( ≈ 0.80/ M) 5 5 6 6 7 7 5 5 8 8 9 9 10 10 5 5 11 11 12 12 5 5 14 16 16 16 16 2

Provider & Model Context Length Input Cost (USD/ M tokens) Output Cost (USD/M tokens) Key strengths/notes xAI Grok 2 (1212) 131 k 2 10 Cohere Command R+ 128 k 3 15 Perplexity (Sonar family) Sonar Pro 200 k 3 15 Sonar Reasoning Pro 128 k 2 8 Sonar Deep Research 200 k 2 8 Sonar Reasoning (general) 128 k 1 5 Sonar (Q&A) 128 k 1 1 R1 1776 177.6 k 2 8 Llama 3.1 Sonar 8B / 70B 128 k ~0.?? (free or minimal) ~0?? Other Llama 3.1 405B 128 k 2.70 2.70 Llama 3.1 70B 128 k 0.90 0.90 Llama 3.1 8B 128 k 0 0 Gemini 2.5 Flash 1 M 0.15 0.60 Gemini 2.0 Flash 1 M 0.10 0.40 Gemini Flash (free) 1 M 0 0 Devstral Small (free) 128 k 0 0 Note : Some pricing values marked with approximations result from per‑token rates in API documentation; we converted them to per‑million tokens for easier comparison. When using these models you pay only for tokens processed (rounded by provider). Pricing may change over time; verify with OpenRouter before production use. Model Details and Recommendations OpenAI Models GPT‑5 Chat – OpenAI’s latest flagship model (released mid‑2025). It offers 400 k token context and improved step‑by‑step reasoning. The model includes test‑time routing to reduce hallucination and 17 17 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 5 5 5 5 5 5 20 20 5 5 5 5 5 5 3

“sycophancy,” and it significantly improves reliability compared to earlier GPT‑4 series . GPT‑5 is ideal for complex reasoning tasks, large documents, and high‑accuracy requirements, but its cost ($1.25/M input and $10/M output tokens ) makes it suitable for scenarios where quality is critical. GPT‑5 Mini – A compact variant of GPT‑5. It preserves much of GPT‑5’s reasoning and instruction-following ability with lower latency and cost ($0.25/M input and $2/M output ). Use GPT‑5 Mini for tasks requiring high quality but lower budget, such as summarization or moderate complexity reasoning. GPT‑5 Nano – Even smaller and faster than GPT‑5 Mini. At $0.05/M input and $0.40/M output , it targets real-time applications and developer tools. However, its reasoning depth is reduced compared to larger GPT‑5 models , so it is best for quick, simple queries or tasks where cost and latency outweigh top performance. GPT‑4o (Omni) – OpenAI’s multimodal model that processes text and images. It offers 128 k context and reduces cost relative to GPT‑4 Turbo (input cost $2.50/M, output cost $10/M) . GPT‑4o is well‑rounded for chat, summarization, coding, and vision tasks. Choose this model for general‑purpose applications requiring multimodal input or improved non‑English performance . GPT‑3.5 Turbo – A cost‑effective baseline model with 16 k context (input cost $0.50/M, output $1.50/M) . It is suited for short conversations, simple classification, or experiments where cost is a priority. Avoid using GPT‑3.5 Turbo for tasks requiring long contexts or advanced reasoning. Anthropic Models Claude Opus 4 (4.1) – Anthropic’s top model. It provides 200 k context and achieves state‑of‑the‑art performance in coding and reasoning tasks (72.5 % on SWE‑Bench Verified) . At $15/M input and $75/M output tokens , it is expensive but delivers exceptional accuracy and reliability. Use Claude Opus when quality is paramount (e.g., complex summarization, legal analysis, coding problems) and budgets allow. Claude Sonnet 4 – A balanced model with 200 k context at $3/M input and $15/M output . It offers a good trade‑off between cost and performance, making it a solid default for high‑quality chat or reasoning tasks that cannot justify Claude Opus costs. Claude Haiku 3.5 – An efficient model for quick responses. At $0.80/M input and $4/M output , it provides 200 k context and delivers fast results. Consider Claude Haiku for interactive chatbots or quick summarization tasks where moderate quality is acceptable. DeepSeek Models DeepSeek V3 and V3.1 – Open‑source models with 163,840 token context. They are competitively priced: V3 costs $0.20/M input and $0.80/M output ; V3.1 charges per token (0.0000002 input, 0.0000008 output) which approximates to similar costs . These models are trained on nearly 15 trillion tokens and provide strong instruction following, coding ability, and hybrid reasoning . They also support tool calling and retrieval, making them versatile alternatives to proprietary models. 1 1 2 3 3 4 4 5 6 6 7 5 8 9 8 4

DeepSeek Coder V2 – A specialized coding model with 128 k context. It achieves high scores on HumanEval (89.9 %) and charges $0.27/M input and $1.10/M output tokens . Choose this model for programming tasks when you need structured code generation or FIM (fill‑in‑the‑middle) support. DeepSeek Chat (free) – A free general‑purpose chat model. With 16 k context and no cost , it is suitable for minimal‑stakes tasks or development and testing. Mistral Models Mistral Large 2 – A European model with 128 k context, priced at $2/M input and $6/M output . It excels at reasoning, code generation, JSON output, and multilingual tasks across many programming languages . Mistral Large offers performance comparable to GPT‑4 Turbo at a lower cost and with data locality advantages (for EU customers). Mistral Medium 3.1 – At $0.40/M input and $2/M output , this model provides 131 k context and high performance at lower cost. It supports coding, STEM reasoning, and enterprise adaptation, making it a cost‑effective general model . Codestral – A smaller code‑centric model (32 k context) priced at $1/M input and $3/M output . It is optimized for FIM and code generation tasks. Mistral Small 3.1 – A free, open‑source model with 128 k context. It is multimodal and multilingual with low latency . Use Mistral Small for on‑device or specialized applications where free models suffice. Z.AI GLM Models Z.AI’s GLM models use a mixture‑of‑experts architecture with thinking and non‑thinking modes. The GLM‑4.5 series offers 131 k context length and pricing roughly $0.40/M input and $1.60/M output (based on 0.0000004 and 0.0000016 per token) . These models provide strong reasoning and multilingual capabilities. GLM‑4.5 Air is a lower‑cost variant with slightly lower performance. These models may also be available in free versions for smaller tasks . When you need a Chinese‑centric or multi‑language model with step‑by‑step reasoning, GLM models can be competitive. Qwen Models Qwen uses a mixture‑of‑experts (MoE) architecture to dynamically allocate different expert modules. Qwen‑3‑30B offers 262 k context with costs around $0.10/M input and $0.30/M output 【 598919971721685†L308-L406 】 . Qwen‑3‑235B (Thinking) is a larger variant (235 B parameters) with pricing ~0.078/M input and 0.312/M output 【 598919971721685†L308-L406 】 . Both models support strong reasoning, multilingual tasks, and code generation; the thinking variant emphasises step‑by‑step reasoning 【 598919971721685†L308-L406 】 . Qwen QwQ 32B , a free model, targets math and reasoning tasks and uses reinforcement learning to reduce hallucination . Use Qwen when your tasks involve Chinese content or require advanced reasoning at competitive prices. 10 5 11 11 12 12 5 13 14 14 15 5

AI21 Jamba Models AI21’s Jamba Large and Jamba Mini are mixture‑of‑experts models offering 256 k context. They are efficient for RAG workflows thanks to their combination of dense and MoE layers. Jamba Large costs ~0.60/ M input and 2.40/M output tokens , while Jamba Mini costs ~0.20/M input and 0.80/M output . Both models provide long context at moderate cost, making them suitable for document summarization and search‑enhanced queries. xAI Grok Grok 2 (1212) – Developed by xAI, Grok 2 features 131 k context and costs $2/M input and $10/M output . It emphasizes enhanced accuracy, instruction adherence, and multilingual support . The model is described as flexible and steerable, offering user‑friendly control over outputs. Consider Grok when you need a general‑purpose model with more libertarian content policies compared to other providers. Cohere Command Models Command R+ – Cohere’s flagship model with 128 k context and 104 B parameters, priced at $3/M input and $15/M output . It is optimized for role‑playing, consumer chat use‑cases, and retrieval‑augmented generation (RAG) scenarios and supports multiple languages . If your application involves chatbots or RAG with long context, Command R+ is a strong candidate. Perplexity Sonar Family Perplexity offers its own models primarily for internal use but accessible through OpenRouter. Sonar Pro provides 200 k context at $3/M input and $15/M output . Sonar Reasoning Pro uses DeepSeek R1 and charges $2/M input and $8/M output ; it emphasizes reasoning and research tokens. Sonar Deep Research has similar pricing but includes additional search fees . Sonar Reasoning is a general model (128 k context, $1/M input, $5/M output) with a subscription requirement . The basic Sonar Q&A model charges $1/M for both input and output with subscription . R1 1776 is a fairness‑oriented variant (177.6 k context) costing $2/M input and $8/M output . Finally, Llama 3.1 Sonar variants (8B and 70B) offer cost‑effective open‑source performance . Use these models when you need integrated search or reasoning tokens and are comfortable with the subscription pricing model. Gemini Models (by Google DeepMind) Gemini 2.5 Flash offers an impressive 1 million token context at $0.15/M input and $0.60/M output . It is designed for speed and reasoning, making it a great candidate for long documents or chaining tasks requiring large contexts. Gemini 2.0 Flash is an earlier version costing $0.10/M input and $0.40/M output . Gemini Flash (free) provides multimodal capability with 1 M context at no cost ; it is best for low‑stakes experimentation or tasks requiring large context but not top performance. Llama Models (Meta & Perplexity) Meta’s Llama models include Llama 3.1 405B (128 k context; $2.70/M input and $2.70/M output ), Llama 3.1 70B ($0.90/M input and output ), and Llama 3.1 8B (free) . These open‑source models deliver strong general performance, especially on tasks requiring shorter contexts or offline deployment. 16 16 17 17 18 18 19 19 19 19 19 19 19 20 5 5 5 5 5 6

They are often used for fine‑tuning and private deployment. Perplexity’s Llama 3.1 Sonar variants integrate Llama models with search and reasoning enhancements . Other Notable Models Gemini Flash (free) is a free multimodal model with 1 M context. It is ideal for tasks like summarizing long transcripts and images when cost is critical. Devstral Small is a free coding model (128 k context) that can handle many programming tasks . Cost‑Saving Strategies When building applications on OpenRouter, costs can multiply quickly. The TeamDay.ai article suggests several methods to manage costs: Match model to task : Use high‑end models (e.g., Claude Opus or GPT‑5) only when the task demands top quality, such as legal reasoning or complex code synthesis. For simpler tasks, choose cheaper models like GPT‑3.5, Gemini Flash, DeepSeek V3, Mistral Medium, or free models . Workflow chaining : Break tasks into smaller steps and use different models for each. For example, a cheap model might extract key points, a medium‑tier model could expand them, and a high‑end model could refine the final answer. This can reduce cost by 30–60 % . Caching responses : Store outputs of frequently used prompts (e.g., summarization templates) and reuse them to avoid repeated API calls . Batching requests : Combine multiple prompts into one API call when possible; providers often round up to the nearest token or request, so batching can reduce overhead . Model Selection Guidelines General chat & everyday tasks – Use GPT‑4o, Mistral Medium 3.1, Qwen‑3‑30B, or Sonar models for high quality at moderate cost. For cost‑sensitive tasks, GPT‑3.5 Turbo, Mistral Small, or DeepSeek Chat are sufficient. Long documents & summarization – Choose Gemini Flash (free or paid) or GPT‑5 for extremely long contexts (up to 1 M tokens). DeepSeek V3/V3.1 and Jamba models also provide long contexts (~164 k and 256 k, respectively). Coding & technical reasoning – Opt for DeepSeek Coder V2, Claude Opus 4, or Mistral Large 2 for highest performance. For budget tasks, Codestral or Devstral Small work well. Multilingual support – GPT‑4o, GPT‑5, Claude models, Mistral Large 2, Qwen models, and xAI Grok provide strong support for many languages 【 598919971721685†L308-L406 】 . Multimodal tasks – GPT‑4o and Gemini Flash handle images natively; Mistral Small 3.1 and some Qwen models also support multimodal input . 19 • • 5 1. 21 2. 21 3. 21 4. 21 1. 2. 3. 4. 4 11 5. 13 7

Reasoning & logic – For deep reasoning or chain‑of‑thought tasks, select GPT‑5, Claude Opus, Qwen‑3‑235B (Thinking), or GLM‑4.5. Sonar Reasoning Pro and Sonar Deep Research also target reasoning heavy tasks . Real‑time or low‑latency applications – GPT‑5 Nano, Mistral Small 3.1, and Gemini Flash deliver fast responses with reasonable quality, suitable for chatbots or interactive systems . Conclusion OpenRouter aggregates a broad range of LLMs across multiple providers, giving developers flexibility to choose the best model for each task. This manual summarises available models as of August 26 2025, including their context lengths, costs, and key strengths. Use this guide to balance quality, cost, and performance for your application. Always verify current pricing on OpenRouter.ai, as rates and model availability may change. OpenRouter https://openrouter.ai/openai/gpt-5 OpenRouter https://openrouter.ai/openai/gpt-5-mini OpenRouter https://openrouter.ai/openai/gpt-5-nano OpenRouter https://openrouter.ai/openai/gpt-4o Top AI Models on OpenRouter 2025: Cost vs Performance Analysis | Complete Guide - TeamDay.ai - AI For The Winning Teams | Boost Productivity and Teamwork https://www.teamday.ai/blog/top-ai-models-openrouter-2025 OpenRouter https://openrouter.ai/deepseek/deepseek-chat openrouter.ai https://openrouter.ai/api/v1/models OpenRouter https://openrouter.ai/mistralai/mistral-large OpenRouter https://openrouter.ai/mistralai/mistral-medium-3.1 Open Router Models and its Strengths - Updated 20th March 2025 | Triplo AI - International https://documentation.triplo.ai/faq/open-router-models-and-its-strengths OpenRouter https://openrouter.ai/x-ai/grok-2-1212 OpenRouter https://openrouter.ai/cohere/command-r-plus 6. 19 7. 3 13 1 2 3 4 5 6 7 10 20 21 8 9 14 16 11 12 13 15 17 18 8

OpenRouter https://openrouter.ai/perplexity 19 9